{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4_Q3 b).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGsaJuVnX2co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_dataset = fetch_20newsgroups(subset='train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkn483SNX9go",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97b8e538-dfc6-4511-c9f0-250997c206a2"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "phi = vectorizer.fit_transform(newsgroups_dataset.data).transpose()\n",
        "phi.shape"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130107, 11314)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCis9OwZYAmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "m = 130107\n",
        "k = 100\n",
        "theta = np.random.rand(m, k) \n",
        "theta,_= np.linalg.qr(theta)\n",
        "phi_transpose = phi.transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvX-SK7VU6Xf",
        "colab_type": "text"
      },
      "source": [
        "Applying PCA to transform the data matrix into 100 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7xomECEYKMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (1,30):\n",
        "  temp = phi_transpose @ theta\n",
        "  theta = phi @ temp\n",
        "  theta,_ = np.linalg.qr(theta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnnGHFypYNhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a76bca9a-7bca-4480-e7e0-765dc53fa9e5"
      },
      "source": [
        "y = theta.transpose() @ phi\n",
        "y.shape"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 11314)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7aG_0XiiuH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "Cluster_means = GaussianMixture(n_components = 20).fit(y.transpose()).means_\n",
        "thetameans = theta @ Cluster_means.transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8kVWlyCVEl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Using GaussianMixture library of scikit learn to create 20 clusters "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XDzvCh2oPPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = []\n",
        "for i in range(0, 20):\n",
        "    res.append(thetameans.transpose()[i].argsort()[-10:][::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm5y1Nd6VkqQ",
        "colab_type": "text"
      },
      "source": [
        "Taking top 10 words of each class from the mean vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0xuoo_WEMFf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "315f744b-aa1c-401c-e321-7d49c441bd8b"
      },
      "source": [
        "vocab = vectorizer.vocabulary_\n",
        "vocab_keyvalue = {value : key for key, value in vocab.items()}\n",
        "for i in range(0,20):\n",
        "  temp = \"\"\n",
        "  for j in range(0,10):\n",
        "    temp+= vocab_keyvalue.get(res[i][j]) + \",\"\n",
        "  print(\"Class :\" + str(i) + \" top words: \" + temp + \" \")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class :0 top words: the,to,and,of,is,it,drive,edu,for,in, \n",
            "Class :1 top words: the,of,to,and,that,is,in,god,you,it, \n",
            "Class :2 top words: the,in,to,of,and,edu,team,game,he,is, \n",
            "Class :3 top words: the,edu,to,of,for,and,it,in,is,you, \n",
            "Class :4 top words: henry,toronto,zoo,spencer,zoology,the,of,to,edu,work, \n",
            "Class :5 top words: the,to,of,and,for,is,it,windows,edu,in, \n",
            "Class :6 top words: sandvik,kent,apple,newton,the,com,ksand,alink,and,that, \n",
            "Class :7 top words: intercon,amanda,walker,clipper,systems,com,corporation,the,encryption,herndon, \n",
            "Class :8 top words: keith,caltech,sgi,livesey,the,wpd,solntze,that,jon,morality, \n",
            "Class :9 top words: the,he,to,of,in,and,edu,that,is,was, \n",
            "Class :10 top words: the,israel,of,israeli,to,in,and,that,jews,is, \n",
            "Class :11 top words: the,of,to,edu,in,that,is,and,you,it, \n",
            "Class :12 top words: access,digex,the,pat,net,express,online,communications,com,prb, \n",
            "Class :13 top words: pitt,geb,gordon,banks,the,cs,is,it,edu,cadre, \n",
            "Class :14 top words: the,to,and,in,of,it,you,is,com,car, \n",
            "Class :15 top words: columbia,gld,cunixb,cc,dare,gary,the,edu,to,of, \n",
            "Class :16 top words: the,nasa,to,gov,space,of,in,and,is,for, \n",
            "Class :17 top words: the,to,of,key,and,is,that,clipper,chip,encryption, \n",
            "Class :18 top words: the,uk,to,of,is,ac,in,and,it,that, \n",
            "Class :19 top words: the,to,of,that,and,in,is,you,it,for, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFYepwK8Vuvt",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the article and prepositions of the english dictionary are the top frequent words across all the classes. This is intuitive."
      ]
    }
  ]
}