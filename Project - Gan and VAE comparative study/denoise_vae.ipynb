{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of denoise_vae.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXCkM5UXCKmV",
        "outputId": "f3de9c41-ea44-4965-f42f-e022903fc39e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!pip install tensorflow==1.14.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.28.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaW7XvmDAzUL"
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A8gcu6KJ6Ol"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xt0lNyoBMtL"
      },
      "source": [
        "# train the VAE on MNIST digits\n",
        "noise_factor = 0.5\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "num_train=len(x_train)\n",
        "num_test=len(x_test)\n",
        "x_train = x_train.reshape((num_train, 28,28,1))\n",
        "x_test = x_test.reshape((num_test, 28,28,1))\n",
        "noise_train = x_train + noise_factor * np.random.randn(*x_train.shape)\n",
        "noise_test = x_test + noise_factor * np.random.randn(*x_test.shape)\n",
        "# Clip the images to be between 0 and 1\n",
        "noise_train = np.clip(noise_train, 0., 1.).astype('float32')\n",
        "noise_test = np.clip(noise_test, 0., 1.).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx7Enta-BPek",
        "outputId": "c5ad7413-2aee-459c-f165-61066d66ad11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        }
      },
      "source": [
        "n_images = 6\n",
        "import scipy.signal as signal\n",
        "figure = np.zeros((28*3 , 28 * n_images))\n",
        "# Display\n",
        "showidx=np.random.randint(0,num_train,n_images)\n",
        "for i,idx in enumerate (showidx):\n",
        "    figure[0: 28,i *28: (i + 1) * 28] = np.reshape(x_train[idx], [28, 28])\n",
        "    figure[28: 56,i *28: (i + 1) * 28] = np.reshape(noise_train[idx], [28, 28])\n",
        "    figure[28 * 2: 28 * 3,i *28: (i + 1) * 28] = signal.medfilt2d(np.reshape(noise_train[idx], [28, 28]),[3,3])\n",
        "plt.figure(figsize=(28*3, 28*n_images))\n",
        "plt.imshow(figure, cmap='Greys_r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 6048x12096 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYLdheX6BWPw"
      },
      "source": [
        "# Training Parameters\n",
        "%matplotlib inline\n",
        "learning_rate = 0.001\n",
        "num_steps = 2500\n",
        "batch_size = 128\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 784 # MNIST data input (img shape: 28*28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcvkvvnQBaFj"
      },
      "source": [
        "# Create the neural network\n",
        "def AE(x_dict, reuse, is_training):\n",
        "    \n",
        "    # Define a scope for reusing the variables\n",
        "    with tf.variable_scope('autoencoder', reuse=reuse):\n",
        "        # TF Estimator input is a dict, in case of multiple inputs\n",
        "        x = x_dict['noise']\n",
        "        \n",
        "        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
        "        # Reshape to match picture format [Height x Width x Channel]\n",
        "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
        "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "\n",
        "        conv1 = tf.layers.conv2d(x, 32, 3, activation=tf.nn.relu)\n",
        "        conv2 = tf.layers.conv2d(conv1, 32, 3, activation=tf.nn.relu)\n",
        "        pool1 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
        "        conv3 = tf.layers.conv2d(pool1, 64, 3, activation=tf.nn.relu)\n",
        "        pool2 = tf.layers.max_pooling2d(conv3, 2, 2)\n",
        "        # Flatten the data to a 1-D vector for the fully connected layer\n",
        "        fc1 = tf.contrib.layers.flatten(pool2)\n",
        "        fc1=tf.reshape(fc1,shape=[-1,1,1,1600])\n",
        "        conv_0T = tf.layers.Conv2DTranspose(128,(1, 1),activation=tf.nn.relu)(fc1)#1*1\n",
        "        conv_1T = tf.layers.Conv2DTranspose(64,(3, 3), activation=tf.nn.relu)(conv_0T)#3*3\n",
        "        conv_2T = tf.layers.Conv2DTranspose(64,(3, 3), activation=tf.nn.relu)(conv_1T)#5*5\n",
        "        conv_3T = tf.layers.Conv2DTranspose(48,(3, 3), strides=(2, 2),padding='same',activation=tf.nn.relu)(conv_2T)#10*10\n",
        "        conv_4T = tf.layers.Conv2DTranspose(48,(3, 3), activation=tf.nn.relu)(conv_3T)#12*12\n",
        "        conv_5T = tf.layers.Conv2DTranspose(32,(3, 3), strides=(2, 2),padding='same',activation=tf.nn.relu)(conv_4T)#24*24\n",
        "        conv_6T = tf.layers.Conv2DTranspose(16,(3, 3), activation=tf.nn.relu)(conv_5T)#26*26\n",
        "        out = tf.layers.Conv2DTranspose(1,(3, 3),activation=tf.nn.sigmoid)(conv_6T)#28*28\n",
        "    #print(tf.layer.all_layers)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-XsXhXPBdLo"
      },
      "source": [
        "def AE_loss(x_reconstructed,x_true):\n",
        "    encode_decode_loss = x_true * tf.log(1e-10 + x_reconstructed) \\\n",
        "                         + (1 - x_true) * tf.log(1e-10 + 1 - x_reconstructed)\n",
        "    encode_decode_loss = -tf.reduce_sum(encode_decode_loss, 1)\n",
        "    return tf.reduce_mean(encode_decode_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF6Z2p_nBfzK"
      },
      "source": [
        "# Define the model function (following TF Estimator Template)\n",
        "def model_fn(features, mode):\n",
        "    \n",
        "    # Build the neural network\n",
        "    # Because Dropout have different behavior at training and prediction time, we\n",
        "    # need to create 2 distinct computation graphs that still share the same weights.\n",
        "    decoder_train = AE(features, reuse=False, is_training=True)\n",
        "    decoder_test = AE(features,reuse=True, is_training=False)\n",
        "    \n",
        "    flattendecoder=tf.reshape(decoder_train, shape=[-1, num_input, 1])\n",
        "    flatteninput=tf.reshape(features['images'], shape=[-1, num_input, 1])\n",
        "    \n",
        "    # If prediction mode, early return\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(mode, predictions=decoder_test) \n",
        "    \n",
        "    # Define loss and optimizer\n",
        "    #with tf.name_scope('Loss'):\n",
        "    loss_op = AE_loss(flattendecoder,flatteninput)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
        "    \n",
        "    # Evaluate the accuracy of the model\n",
        "    #acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
        "    \n",
        "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
        "    # the different ops for training, evaluating, ...\n",
        "    #tf.summary.scalar(\"loss\", loss_op)\n",
        "    estim_specs = tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      loss=loss_op,\n",
        "      train_op=train_op,\n",
        "      #eval_metric_ops={'accuracy': acc_op}\n",
        "    )\n",
        "    \n",
        "    return estim_specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3hPOc2vBjNe",
        "outputId": "d9a521f0-9e92-4493-f06c-a9a243db013f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# Build the Estimator\n",
        "#logs_path = '/tmp/tensorflow_logs/example/'\n",
        "#summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
        "model = tf.estimator.Estimator(model_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp03p0mt4x\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp03p0mt4x', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8731011c18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCwD9Q37BpGz",
        "outputId": "0926461d-7e00-4b9d-85e1-91f6aa3bd64c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Define the input function for training\n",
        "\n",
        "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images':x_train,'noise':noise_train},\n",
        "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
        "# Train the Model\n",
        "model.train(input_fn, steps=num_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f030208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f030208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f030208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f030208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f030208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f030208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f030208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f030208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f030208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f873049c208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f873049c208>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f873049c208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f873049c208>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8736f257f0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872b8ed1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872b8ed1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872b8ed1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872b8ed1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872b8ed1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872b8ed1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872b8ed1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872b8ed1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872b8ed1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872effb710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872effb710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872effb710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872effb710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87316a0b70>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp03p0mt4x/model.ckpt.\n",
            "INFO:tensorflow:loss = 543.4264, step = 1\n",
            "INFO:tensorflow:global_step/sec: 1.99516\n",
            "INFO:tensorflow:loss = 208.42664, step = 101 (50.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.00185\n",
            "INFO:tensorflow:loss = 197.93427, step = 201 (49.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.00306\n",
            "INFO:tensorflow:loss = 172.3943, step = 301 (49.926 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.00197\n",
            "INFO:tensorflow:loss = 137.6627, step = 401 (49.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.00311\n",
            "INFO:tensorflow:loss = 117.4396, step = 501 (49.922 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.93101\n",
            "INFO:tensorflow:loss = 110.58569, step = 601 (51.786 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.99998\n",
            "INFO:tensorflow:loss = 111.557236, step = 701 (50.003 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.99781\n",
            "INFO:tensorflow:loss = 102.684296, step = 801 (50.052 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.00802\n",
            "INFO:tensorflow:loss = 97.91228, step = 901 (49.800 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.00205\n",
            "INFO:tensorflow:loss = 93.92848, step = 1001 (49.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.00094\n",
            "INFO:tensorflow:loss = 94.49172, step = 1101 (49.976 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1197 into /tmp/tmp03p0mt4x/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 1.9923\n",
            "INFO:tensorflow:loss = 92.587746, step = 1201 (50.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.00464\n",
            "INFO:tensorflow:loss = 86.79187, step = 1301 (49.886 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.01468\n",
            "INFO:tensorflow:loss = 86.256096, step = 1401 (49.635 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.01204\n",
            "INFO:tensorflow:loss = 85.74668, step = 1501 (49.700 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.01581\n",
            "INFO:tensorflow:loss = 90.2417, step = 1601 (49.607 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.01612\n",
            "INFO:tensorflow:loss = 86.15877, step = 1701 (49.601 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.02133\n",
            "INFO:tensorflow:loss = 84.06949, step = 1801 (49.475 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.95254\n",
            "INFO:tensorflow:loss = 78.89926, step = 1901 (51.217 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.02067\n",
            "INFO:tensorflow:loss = 84.51067, step = 2001 (49.486 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.02409\n",
            "INFO:tensorflow:loss = 79.802826, step = 2101 (49.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.01682\n",
            "INFO:tensorflow:loss = 80.704895, step = 2201 (49.583 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.02423\n",
            "INFO:tensorflow:loss = 79.73636, step = 2301 (49.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.02134\n",
            "INFO:tensorflow:loss = 75.43733, step = 2401 (49.473 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2404 into /tmp/tmp03p0mt4x/model.ckpt.\n",
            "INFO:tensorflow:Saving checkpoints for 2500 into /tmp/tmp03p0mt4x/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 79.74367.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f8731011390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXRuHXPEJ8gB",
        "outputId": "d94a7d2b-5718-4c51-cd87-5dbd00ef358d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Evaluate the Model\n",
        "# Define the input function for evaluating\n",
        "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images': x_test,'noise': noise_test}, \n",
        "    batch_size=batch_size, shuffle=False)\n",
        "# Use the Estimator 'evaluate' method\n",
        "model.evaluate(input_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87313cdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87313cdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87313cdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87313cdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87313cdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87313cdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87313cdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87313cdb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87313cdb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872ba1d5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872ba1d5f8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872ba1d5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872ba1d5f8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872edab470>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f07b0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f07b0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f07b0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f07b0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f07b0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f07b0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f07b0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f07b0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f07b0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f87306bbe48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f87306bbe48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f87306bbe48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f87306bbe48>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f87306ca978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-04-27T02:21:44Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp03p0mt4x/model.ckpt-2500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2020-04-27-02:21:59\n",
            "INFO:tensorflow:Saving dict for global step 2500: global_step = 2500, loss = 79.04325\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2500: /tmp/tmp03p0mt4x/model.ckpt-2500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'global_step': 2500, 'loss': 79.04325}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTYONhYwX496",
        "outputId": "35a157f5-dff9-44ce-8b52-100280d8ad4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(num_test,n_images)\n",
        "\n",
        "# Predict single images\n",
        "# Get images from test set\n",
        "showidx=np.random.randint(0,num_test,n_images)\n",
        "test_images = x_test[showidx]\n",
        "noise_images = noise_test[showidx]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRTuu7pgilkK"
      },
      "source": [
        "figure = np.zeros((28 * 4, 28 * n_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgauT4CDjbXg"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYIJuHlpjLw1",
        "outputId": "29871832-b141-42a4-e212-43eb9a22160a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "query = x_test[7699]\n",
        "#plt.imshow(query.reshape(28,28), cmap='gray')\n",
        "X_test_new = np.delete(x_test, 7699, axis=0)\n",
        "noise_test_new = np.delete(noise_test, 7699, axis=0)\n",
        "print(X_test_new.shape)\n",
        "\n",
        "# Prepare the input data\n",
        "input_fn_new = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images': X_test_new,'noise': noise_test_new}, shuffle=False)\n",
        "preds_new = list(model.predict(input_fn_new))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9999, 28, 28, 1)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f278198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f278198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f278198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f278198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872f278198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f278198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f278198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f278198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872f278198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872f297f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872f297f60>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872f297f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872f297f60>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f873950d828>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872ecd4668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872ecd4668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872ecd4668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872ecd4668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872ecd4668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872ecd4668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872ecd4668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872ecd4668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872ecd4668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872ecc5400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872ecc5400>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872ecc5400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872ecc5400>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872ecfcd30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp03p0mt4x/model.ckpt-2500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRoxvdK3fneh",
        "outputId": "fcdea24b-cbfd-40d4-b06a-e2b5df2befb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "noise_query = noise_test[7699]\n",
        "#query\n",
        "input_fn_new = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images': query,'noise': noise_query}, shuffle=False)\n",
        "query_code = list(model.predict(input_fn_new))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872acafac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872acafac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872acafac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872acafac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872acafac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872acafac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872acafac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872acafac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87305bee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87305bee10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87305bee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87305bee10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87305bee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87305bee10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87305bee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f87305bee10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87305bee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87305bee10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87305bee10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f87305bee10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8728fc52b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8728fc52b0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8728fc52b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8728fc52b0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f8731466588>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872965d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872965d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872965d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872965d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f872965d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872965d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872965d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872965d6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f872965d6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872980b358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872980b358>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872980b358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f872980b358>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "WARNING: Entity <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv2DTranspose.call of <tensorflow.python.layers.convolutional.Conv2DTranspose object at 0x7f872967bda0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp03p0mt4x/model.ckpt-2500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQyzG_-VlJOO",
        "outputId": "04bde5d9-599e-4be6-9775-9feff0ffa901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "preds_new_np = np.array(preds_new)\n",
        "query_code_np = np.array(query_code)\n",
        "print(preds_new_np.shape)\n",
        "print(query_code_np.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9999, 28, 28, 1)\n",
            "(1, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tse448XUanfE",
        "outputId": "96a2a6f4-917b-4099-8cab-e893bcf4d51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "n_neigh = 5\n",
        "codes = preds_new_np.reshape(-1, 784); print(codes.shape)\n",
        "#query_code = query_code.reshape(1, 4*4*8); print(query_code.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9999, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvTMV4iOl9TF"
      },
      "source": [
        "nbrs = NearestNeighbors(n_neighbors=n_neigh).fit(codes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zqBkCl3mHJg",
        "outputId": "a4e41bbd-9aa3-4e5d-c6f1-2d08c99684e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "query_codes = query_code_np.reshape(-1, 784); print(query_codes.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9u4bEIbmVox",
        "outputId": "fbf87537-c404-46c7-a20a-552cd5c57077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "distances, indices = nbrs.kneighbors(np.array(query_codes))\n",
        "closest_images = x_test[indices]\n",
        "closest_images = closest_images.reshape(-1,28,28,1); print(closest_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jhLBf1CmniN",
        "outputId": "5e8a0405-8d7a-4c56-8f69-0d57e62a9483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(query.reshape(28,28), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f873153fa58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVXF6DH7mqkC",
        "outputId": "eb102712-d2ed-4e1c-9f71-8a398d4b5b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "for i in range(n_neigh):\n",
        "    # display original\n",
        "    ax = plt.subplot(1, n_neigh, i+1)\n",
        "    plt.imshow(closest_images[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABG0AAADSCAYAAADwvT10AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAYNklEQVR4nO3de5CWddnA8WcVAUnQEFAQkEzURlJIxQNiOHhWVLQgRTIlczCnJkWYQSDJMXVK0jE1B0yKgzimIiqShzSRBhQdiXA6yHgAZIBF4hAIKPv+8b5/NLrX711unt39Pbufz5/Pl+e+f4Q3z+7l5lVVU1NTAgAAACAvezX2AQAAAAD4IkMbAAAAgAwZ2gAAAABkyNAGAAAAIEOGNgAAAAAZMrQBAAAAyFCL3fnFVVVV9oPTrNXU1FQ19hlq49mkucvx2fRcQqm6pqamY2Mf4vM8m+DZhEzV+mz6SRsAAOrDB419AKBWnk3IU63PpqENAAAAQIYMbQAAAAAyZGgDAAAAkCFDGwAAAIAMGdoAAAAAZMjQBgAAACBDhjYAAAAAGTK0AQAAAMiQoQ0AAABAhgxtAAAAADJkaAMAAACQIUMbAAAAgAwZ2gAAAABkyNAGAAAAIEOGNgAAAAAZMrQBAAAAyJChDQAAAECGDG0AAAAAMmRoAwAAAJAhQxsAAACADBnaAAAAAGTI0AYAAAAgQ4Y2AAAAABkytAEAAADIkKENAAAAQIZaNPYBmrKqqqqwfetb3wrbhAkTan396KOPLvs53njjjbDNmzcvbNEZodJ985vfDNtdd91V6+t9+vQJ3zNr1qywzZ07N2wzZswIGzQ3e+0V/zumYcOG1fp66nPq8MMPD9vSpUvD1q9fv7Bt3rw5bFDJDjjggLClnqXoGayurg7fs3LlyrA98MADYVu9enXYgLrZf//9wzZx4sSwdevWLWyDBw8OW+p71E8++SRsJ598ctjefvvtsFUyP2kDAAAAkCFDGwAAAIAMGdoAAAAAZMjQBgAAACBDhjYAAAAAGaqqqamp+y+uqqr7L6Z01FFHhW3ZsmVlvdfWrVvDtmXLlrB16tQpbJ9++mnY7r333rCl/uvilb5do6amJv7PnDciz2b5TJs2LWyHHXZYra/37NkzfE/79u0LnWPy5MlhGzlyZKFrNmU5Ppuey92Tela++93vhi3a6lYfrr766rD97ne/a7BzVJA3a2pqjm/sQ3yeZ/OLDj744LA988wzYUttTywitSnuzTffDNsVV1wRtr///e97dKYmyrPZjHXs2LHW15944onwPaeeemrYdu3aVegcqa+5p0yZErbXXnut0P0qRK3Ppp+0AQAAAMiQoQ0AAABAhgxtAAAAADJkaAMAAACQIUMbAAAAgAwZ2gAAAABkyMrvPXTuueeG7amnngrb3nvvXdZzfP/73w/bn/70p7DNnTs3bKmV5SnDhg0L26xZswpdMxc5rhUulTyb5XTBBReELXqWfvzjH4fvue6668LWuXPnsO3cuTNszz77bNiuvfbasK1fvz5slS7HZ9Nz+UW9e/cO28MPPxy2Y445pj6Os9vefffdsJ1xxhlhW7FiRX0cpxJYK5yRTp06hS211vu4444rdL8PP/yw1tfbt28fvqdt27ZhS33PsmHDhrCdc845YVu8eHHYmjjPZhM3ePDgsE2aNKnW17t37x6+p6oq/jJrd+YJ/23mzJlhGz58eKFrNgFWfgMAAABUCkMbAAAAgAwZ2gAAAABkyNAGAAAAIEOGNgAAAAAZMrQBAAAAyJCV33WQWss7Z86csH3jG98odL+lS5fW+vrrr78evuemm24K28aNG8OWWgf32GOPhS219u2VV14J29ChQ8NWXV0dtlzkuFa4VGq+z2ZRl112WdjGjRsXtgMOOKDW1w866KBC55g8eXLYfvCDH4Qt9ff2ggULwpZaZ7558+awVYIcn83m+lymPjPffvvtsHXo0KHQ/f7zn//U+vqyZcvC9/Tt27fQvVLee++9sN13331h+9WvflX2s2TEWuEGtt9++4Vt/vz5YTvmmGPClvrMeeSRR8I2ceLEWl9ftWpV+J7nn38+bKecckrYUlJfBw8YMCBsf/3rXwvdr0J4NpuAn/70p2G7+eabw7ZkyZJaX58wYUL4ntTn94svvhi2Hj16hO2zzz4L21lnnRW2hQsXhq0JsPIbAAAAoFIY2gAAAABkyNAGAAAAIEOGNgAAAAAZMrQBAAAAyJChDQAAAECGrPyugz/+8Y9hO+OMMwpdM7V28ZJLLqn19Y8//rjQvYr6zW9+E7Zrrrmm0DUfffTRsF1++eWFrtmQclwrXCo132ezRYsWYUut7h4/fnyh+23atGm3z5FyxBFHhO24444LW2rFaps2bcI2ZcqUsI0aNSpslbAOPMdnsyk/l/369Qvb9OnTw9a9e/dC91u/fn3Y+vfvX+vrK1euDN8zYsSIsNXHCu6dO3eG7c477wxb6nN49erVe3SmBmKtcAM79thjw/bWW28Vuubjjz8etiFDhhS6ZuScc84J27PPPlvWe5VKpdKTTz4Ztu9973th27JlS9nP0sA8mxXi0ksvDdu0adPCllpZf9FFF9X6+po1a+p+sP8ybNiwsKW+f+3SpUvYbr/99rBF3yuXSqXSa6+9FrYKYeU3AAAAQKUwtAEAAADIkKENAAAAQIYMbQAAAAAyZGgDAAAAkCFDGwAAAIAMWfn9f1JrSBcsWBC21Kqy1IrPjh07hi2X9bqp39uKFSsKXfNf//pX2E477bSwrV27ttD9yi3HtcKlUtN+NlP69u0btr/85S9hS60PHjNmTNgWL15c6+upFcFLly4N2w033BC2lMGDB4ft4YcfDtt+++0XtkmTJoVt9OjRdTtYI8rx2WzKz+Xs2bPDNmjQoELX3LVrV9hSK0/nzJmz2/fq1atX2K699tqwpdYpp9agF3XzzTeH7Y477ij7/eqBtcIN7LHHHgtbak1uylVXXRW23//+94WuGWndunXY7r333rBdffXVZT1HqVQq3X333WG78cYby36/BubZzEiHDh3Clvp6tkePHmE7++yzw/byyy/X6Vz1bZ999gnbXXfdFbbvfOc7YTvyyCPDtmHDhrodrHFZ+Q0AAABQKQxtAAAAADJkaAMAAACQIUMbAAAAgAwZ2gAAAABkyNAGAAAAIEPNauX3XnvFM6pbbrklbKmVmykvvfRS2M4666xC12xIrVq1Ctv8+fPDdtxxxxW6X2r98T333FPomuWW41rhUqnyn82UI444ImyplYUtWrQI27e//e2wvfrqq2E7/fTTa3191qxZ4XtSa4DffffdsBWVWvk9fPjwsKXWIPbp0ydsK1eurNvB6lmOz2alP5c/+tGPwpZaxZn6rE35+c9/Hrbx48cXuma5pdaT/uxnPwvb6NGjC90vtQb95JNPDtvixYsL3a8eWCtcD3r37h22hQsXhi31z+9nn30WtkMOOSRs69atC1u5tWzZMmypz9o5c+aErU2bNmHbvn172FIrh1P3y4hns4FVVcVfphT92m3YsGFhS31tWgn69u0btgULFoQt9T39bbfdtidHaihWfgMAAABUCkMbAAAAgAwZ2gAAAABkyNAGAAAAIEOGNgAAAAAZMrQBAAAAyFC8E7cJOv74eLNd0bXeW7duDdvFF19c6Jq5SK06TK1aLrrye+DAgWG77777an39008/LXQvKkdq1e/BBx8cthEjRoQttdY7Zfr06bW+fskll4TvqY+13il333132AYPHhy29u3bh23kyJFhK/p3J/nr379/2Iqu9U59Zt5+++2FrtmQdu7cGbZ58+aF7frrrw9bauVw6n/n1BrxIUOGhI3Kl/p6NrXWO+WBBx4IW0Ou9U7ZsWNH2FJfl1544YVhe/HFF8PWqlWrsEVfD5RKpVK7du3CRvP1ta99LWyptd5z584N21NPPbVHZ8rZ66+/HrbFixeHrWvXrvVxnEbnJ20AAAAAMmRoAwAAAJAhQxsAAACADBnaAAAAAGTI0AYAAAAgQ4Y2AAAAABlqViu/DzzwwLJfc+rUqWFLrTatdNEK7lKpVBo1alSha55//vlhO/TQQ2t9ffny5YXuRV5OPfXUsKVWda5atSpsqWezqEMOOaTs1yy3JUuWhG3ixIlhmzRpUtgGDBiwJ0ciYwcddFDYUmuFi0qtoq70z8w///nPYUv9vp955plC90utFW7ZsmWtr6dWJlM5vvKVr5T9mjNnziz7NXOxYMGCsKVWhZ9++ulh23fffcN27rnnhu25554LG5Uv+n6lVCqVZs+eHbZ33nknbMOGDQvbtm3b6nawJubJJ58M27hx48I2cuTI+jhOg/CTNgAAAAAZMrQBAAAAyJChDQAAAECGDG0AAAAAMmRoAwAAAJAhQxsAAACADDW5ld+pFXyjR48u+/1SK4ebsu3bt4eturo6bB06dKiP41Dh7rzzzrB96UtfCtuMGTPq4zjN0q5duwo1Klvbtm3D1r1790LXTH0GvPnmm4WuWeleeeWVsM2fPz9s/fv3D9uZZ54Ztm7dutX6+vLly8P3UDkGDRrU2EeoKKlV988//3zYUiu/99or/vfeY8eODZuV303bqFGjwvbVr341bA8++GDYNm3atEdnaoruv//+sKX+DIYOHRq2Rx99dI/OVN/8pA0AAABAhgxtAAAAADJkaAMAAACQIUMbAAAAgAwZ2gAAAABkqMltjxozZkzYTjvttELXTG2ImjJlSqFrVro1a9aE7aWXXgpb6r/aDbvr1ltvbewjAJ+T2saydu3aBjxJPrZt2xa2jz76qAFPQqUYOHBg2Hr16lXomqlnc9GiRYWuWemmTZsWtuuuuy5shx56aNj233//PToTlWvAgAFhW7duXdhS/6zxRVu2bAnbxo0bw5bamJk7P2kDAAAAkCFDGwAAAIAMGdoAAAAAZMjQBgAAACBDhjYAAAAAGTK0AQAAAMhQk1v53aVLl7Jf88orrwxbdXV12e8H1M3q1asb+whQ0UaMGFH2a/72t78t+zXZPdGf69ixYxv4JNSHmpqaQu+bOnVqeQ/SBKS+jki1bt26ha3onw+VL/Vn/+GHHzbgSZqv1Ncglfxs+kkbAAAAgAwZ2gAAAABkyNAGAAAAIEOGNgAAAAAZMrQBAAAAyJChDQAAAECGmtzK7/rw8ccfN/YRstOuXbuwHXnkkQ14EpqCqqqqQo3d07Zt27DttVc8w7/nnnvq4zhk4MADDyz7NX1mflHXrl3DdvHFF5f9fjNnziz7Nal8w4YNC9usWbMa8CRNW8+ePcN24okn1vr6okWL6us4lNkhhxwSti9/+cthu//+++vjOHxOr169wrZmzZoGPEl5+UkbAAAAgAwZ2gAAAABkyNAGAAAAIEOGNgAAAAAZMrQBAAAAyJChDQAAAECGrPymkEGDBoWtd+/eha75zjvvhM0K2aatpqamUOOLTjrppLDddNNNYVu3bl3YFi5cuEdnguaudevWYWvVqlWha6Y+M1etWlXomuRj+fLlYVu7dm3YOnXqFLbU12fdunUL24oVK8LGF/373/8OWyWvHOZ/HXXUUWHr0qVLA56k+Tr22GPDduGFF4Zt+vTp9XGcBuEnbQAAAAAyZGgDAAAAkCFDGwAAAIAMGdoAAAAAZMjQBgAAACBDhjYAAAAAGbLym1BqDeno0aPLfr9FixaFbcOGDWW/H5XvsssuC9sjjzzSgCfJx6hRo8K27777hi211nvlypV7dCby9cILL4RtxIgRha555plnhm3JkiWFrlkJOnbsGLbHH3+87Pfzmdm0vf/++2GbNm1a2G688cawpdYRp5qV37tn6dKlYUv9uQJ1c8MNN4StdevWYXvuuefq4zgNwk/aAAAAAGTI0AYAAAAgQ4Y2AAAAABkytAEAAADIkKENAAAAQIYMbQAAAAAyZOV3HQwaNChsTXl9adeuXcPWq1evQtd85513wjZmzJhC16T5Ou+888JW6Su/27ZtG7bx48eHLfW/Scoll1xS6H1Utnnz5oXtjTfeCNsJJ5wQth/+8Idhe/jhh8O2fv36sDWk9u3bh6179+5hmzp1ath8ZlJO//znP8t+zZtuuilsV1xxRdg++eSTsp+lIV166aVhO/roo8P22Wefhe2OO+7YozNBc5Faz/3ggw+GbfDgwWFLfRbPmTOnTufKkZ+0AQAAAMiQoQ0AAABAhgxtAAAAADJkaAMAAACQIUMbAAAAgAwZ2gAAAABkyMrvOhg5cmTY9t1337BNmDAhbKlVgeXWuXPnsA0fPjxs11xzTdnPklohm8u6Vxreq6++GraTTjopbBdddFHYRo0aFbZ77703bNu3bw9bEW3atAnbmWeeGbbZs2eHbdeuXWHbunVr2CZOnBi2zZs3h42mK/XnvmLFirClVn6n1mL/4Q9/CFtqTe6OHTvCVkTPnj3DllpZXnR1d1G//vWvw+Yzs/maMWNG2IYMGRK2gQMHhi21QnfWrFlhu/zyy8OW+jxqSKmvFaZNmxa2Vq1ahe2FF14I28svv1y3g1GR5s+fH7Z//OMfYevbt2/YUt9Pbtu2rW4Ha0R777132I4//viwPfnkk2Hr2LFj2FJrvceOHRu2SuYnbQAAAAAyZGgDAAAAkCFDGwAAAIAMGdoAAAAAZMjQBgAAACBDhjYAAAAAGaqqqamp+y+uqqr7L24kvXv3DtvTTz8dti5dupT9LG+99VbYUmtW33vvvVpfL7pqtEOHDmHr0aNHoWumjBs3Lmz3339/2DZu3Fj2s5RbTU1NVWOfoTaV8GymdO3aNWzPPvts2FLPROrvttQ6zo8//jhsDz30UK2vjxgxInxP6vd24oknhq2qKv5HLfV7u+qqq8KWWm1a6XJ8Niv9uTz11FPDllrdnVrT2VylVh+nVow/9dRTYauEz8xSqfRmTU1NvO+1kVT6s5ly4IEHhm3hwoVhO+ywwwrdb8OGDWGL1vm+/fbb4Xs2bdoUttTnaer8V155ZdhSq4pTOnfuHLa1a9cWumYD82zWgwkTJhRq1dXVYRs+fHjYUl/Pfvrpp2Fr165dra937949fM+AAQPCdu6554btnHPOCduaNWvCNmnSpLD98pe/DFsTUOuz6SdtAAAAADJkaAMAAACQIUMbAAAAgAwZ2gAAAABkyNAGAAAAIEOGNgAAAAAZanIrv1NS68Bvu+22sKVWlTVlixcvDtsvfvGLsM2bNy9sW7Zs2aMzNbYc1wqXSpX/bKZccMEFYUut/Dv88MPLfpZoDffu/D1aV9u2bQvbddddF7bZs2eHbfPmzXt0ppzl+Gw25eeyX79+YUv9M9i+ffv6OE6D+dvf/ha21N9Hr776atg++OCDPTpT5qwVzsj+++8ftssvvzxsqdW7LVu23KMzfV70OVsq1c9nbcpDDz0Utuuvvz5sO3bsqI/jlJtns4HdcsstYRs/fnyha7722mth27lzZ9g6dOhQ6+tf//rXw/ekns1FixaF7cUXXwxb6hl7//33w9bEWfkNAAAAUCkMbQAAAAAyZGgDAAAAkCFDGwAAAIAMGdoAAAAAZMjQBgAAACBDzWrld8o+++wTtr59+4YttY74Jz/5SaH7RVatWhW2GTNmhC21onTu3Llh++STT8KWWkfclOW4VrhUatrPZsoBBxwQtqFDh4btvPPOC9v5558ftmjd4UcffRS+Z9asWWF76623wvbKK6+EbfXq1WFrrnJ8Npvrc9muXbuw7b333mE75ZRTwnb22WeHrUePHrW+vmzZsvA9y5cvD9vjjz8etu3bt4dt69atYWvGrBVuArp37x62s846K2zRGuPq6urwPX369Alb6nuW1PP+9NNPh23y5MlhS33Wpv4uqBCezQaW+vw74YQTwvbEE0+E7aCDDtqjM33e1KlTw3brrbeGbe3atWHz2bjbrPwGAAAAqBSGNgAAAAAZMrQBAAAAyJChDQAAAECGDG0AAAAAMmR7FOyGHDfUlEqeTcjx2fRcgg01kCnPJuTJ9igAAACASmFoAwAAAJAhQxsAAACADBnaAAAAAGTI0AYAAAAgQ4Y2AAAAABkytAEAAADIkKENAAAAQIYMbQAAAAAyZGgDAAAAkCFDGwAAAIAMGdoAAAAAZMjQBgAAACBDhjYAAAAAGTK0AQAAAMiQoQ0AAABAhgxtAAAAADJkaAMAAACQIUMbAAAAgAwZ2gAAAABkyNAGAAAAIEOGNgAAAAAZMrQBAAAAyJChDQAAAECGDG0AAAAAMmRoAwAAAJAhQxsAAACADLXYzV9fXSqVPqiPg0AFOLSxD5Dg2aQ5y/XZ9FzS3Hk2IU+eTchTrc9mVU1NTUMfBAAAAID/h/97FAAAAECGDG0AAAAAMmRoAwAAAJAhQxsAAACADBnaAAAAAGTI0AYAAAAgQ4Y2AAAAABkytAEAAADIkKENAAAAQIb+BxokHJx8rOGYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x432 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC4LKBr985uh",
        "outputId": "4bc2ca59-ed93-4abc-c978-a75c06cc0dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train_model, y_train_model), (x_test_model, y_test_model) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train_model = x_train_model.reshape(x_train_model.shape[0], 1, img_rows, img_cols)\n",
        "    x_test_model = x_test_model.reshape(x_test_model.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train_model = x_train_model.reshape(x_train_model.shape[0], img_rows, img_cols, 1)\n",
        "    x_test_model = x_test_model.reshape(x_test_model.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train_model = x_train_model.astype('float32')\n",
        "x_test_model = x_test_model.astype('float32')\n",
        "x_train_model /= 255\n",
        "x_test_model /= 255\n",
        "print('x_train_model shape:', x_train_model.shape)\n",
        "print(x_train_model.shape[0], 'train samples')\n",
        "print(x_test_model.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train_model = keras.utils.to_categorical(y_train_model, num_classes)\n",
        "y_test_model = keras.utils.to_categorical(y_test_model, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train_model, y_train_model,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test_model, y_test_model))\n",
        "score = model.evaluate(x_test_model, y_test_model, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train_model shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 150s 2ms/step - loss: 0.2738 - accuracy: 0.9165 - val_loss: 0.0591 - val_accuracy: 0.9795\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 152s 3ms/step - loss: 0.0909 - accuracy: 0.9733 - val_loss: 0.0408 - val_accuracy: 0.9862\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 150s 2ms/step - loss: 0.0661 - accuracy: 0.9807 - val_loss: 0.0343 - val_accuracy: 0.9880\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0552 - accuracy: 0.9837 - val_loss: 0.0268 - val_accuracy: 0.9914\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0474 - accuracy: 0.9861 - val_loss: 0.0271 - val_accuracy: 0.9909\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 151s 3ms/step - loss: 0.0421 - accuracy: 0.9875 - val_loss: 0.0282 - val_accuracy: 0.9907\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.0275 - val_accuracy: 0.9914\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 0.0253 - val_accuracy: 0.9915\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.0280 - val_accuracy: 0.9915\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 150s 3ms/step - loss: 0.0302 - accuracy: 0.9909 - val_loss: 0.0261 - val_accuracy: 0.9919\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.0254 - val_accuracy: 0.9920\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 149s 2ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.0280 - val_accuracy: 0.9916\n",
            "Test loss: 0.027994768605049465\n",
            "Test accuracy: 0.991599977016449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUPqGvC0PHCF"
      },
      "source": [
        "model.save(\"test_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsveyBPOefEY"
      },
      "source": [
        "def KNN(id, query_code):\n",
        "  query = x_test[id]\n",
        "  plt.imshow(query_code.reshape(28, 28))\n",
        "  #plt.imshow(query.reshape(28,28), cmap='gray')\n",
        "  X_test_new = np.delete(x_test, id, axis=0)\n",
        "  noise_test_new = np.delete(noise_test, id, axis=0)\n",
        "  print(X_test_new.shape)\n",
        "\n",
        "   # Prepare the input data\n",
        "  input_fn_new = tf.estimator.inputs.numpy_input_fn(\n",
        "      x={'images': X_test_new,'noise': noise_test_new}, shuffle=False)\n",
        "  preds_new = list(model.predict(input_fn_new))\n",
        "\n",
        "  #noise_query = noise_test[id]\n",
        "  #query\n",
        "  #input_fn_new = tf.estimator.inputs.numpy_input_fn(\n",
        "  #    x={'images': query,'noise': noise_query}, shuffle=False)\n",
        "  #query_code = list(model.predict(input_fn_new))\n",
        "\n",
        "  preds_new_np = np.array(preds_new)\n",
        "  query_code_np = np.array(query_code)\n",
        "  print(preds_new_np.shape)\n",
        "  print(query_code_np.shape)\n",
        "\n",
        "  from sklearn.neighbors import NearestNeighbors\n",
        "  n_neigh = 10\n",
        "  codes = preds_new_np.reshape(-1, 784); print(codes.shape)\n",
        "\n",
        "  nbrs = NearestNeighbors(n_neighbors=n_neigh).fit(codes)\n",
        "  query_codes = query_code_np.reshape(-1, 784); print(query_codes.shape)\n",
        "  distances, indices = nbrs.kneighbors(np.array(query_codes))\n",
        "  closest_images = x_test[indices]\n",
        "  closest_images = closest_images.reshape(-1,28,28,1); print(closest_images.shape)\n",
        "\n",
        "  plt.figure(figsize=(20, 6))\n",
        "  for i in range(n_neigh):\n",
        "      # display original\n",
        "      ax = plt.subplot(1, n_neigh, i+1)\n",
        "      plt.imshow(closest_images[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      ax.get_xaxis().set_visible(False)\n",
        "      ax.get_yaxis().set_visible(False)\n",
        "      \n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmxKMwRienBW",
        "outputId": "e9ce23ef-5254-4174-ef32-ec192b891272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "showidx=np.random.randint(0,num_test,n_images)\n",
        "test_images = x_test[showidx[0]]\n",
        "noise_images = noise_test[showidx[0]]\n",
        "# Prepare the input data\n",
        "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images': test_images,'noise': noise_images}, shuffle=False)\n",
        "# Use the model to predict the images class\n",
        "preds = list(model.predict(input_fn))\n",
        "figure = np.zeros((28 * 4, 28 * n_images))\n",
        "KNN(showidx[0],preds[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-99ee73e6a255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     x={'images': test_images,'noise': noise_images}, shuffle=False)\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Use the model to predict the images class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshowidx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'ndim'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bknTNFQtKRs3",
        "outputId": "19844fc7-1820-4df2-98c2-fe20f3426fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "# Predict single images\n",
        "# Get images from test set\n",
        "showidx=np.random.randint(0,num_test,n_images)\n",
        "test_images = x_test[showidx]\n",
        "noise_images = noise_test[showidx]\n",
        "# Prepare the input data\n",
        "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={'images': test_images,'noise': noise_images}, shuffle=False)\n",
        "# Use the model to predict the images class\n",
        "preds = list(model.predict(input_fn))\n",
        "figure = np.zeros((28 * 4, 28 * n_images))\n",
        "# Display\n",
        "for i,idx in enumerate (showidx):\n",
        "    figure[0: 28,i *28: (i + 1) * 28] = np.reshape(x_test[idx], [28, 28])\n",
        "    figure[28: 28 * 2,i *28: (i + 1) * 28] = np.reshape(noise_test[idx], [28, 28])\n",
        "    figure[28 * 2: 28 * 3,i *28: (i + 1) * 28] = np.reshape(preds[i], [28, 28])\n",
        "    figure[28 * 3: 28 * 4,i *28: (i + 1) * 28] = signal.medfilt2d(np.reshape(noise_test[idx], [28, 28]),[3,3])\n",
        "plt.figure(figsize=(28 * 4, 28*n_images))\n",
        "plt.imshow(figure, cmap='Greys_r')\n",
        "plt.savefig('result_tf_AE.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-5f5e22db3b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     x={'images': test_images,'noise': noise_images}, shuffle=False)\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Use the model to predict the images class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'ndim'"
          ]
        }
      ]
    }
  ]
}