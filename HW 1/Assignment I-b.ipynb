{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment I-b.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNCDS3WS60Y0SMiwiImouAN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YNYvos2wVkTo","colab_type":"text"},"source":["Reading the class label of train data, generating the arrayDocCount array for saving the count of documents for each class, this would give us the prior probability."]},{"cell_type":"code","metadata":{"id":"9fQpGXBmKPK1","colab_type":"code","colab":{}},"source":["trainlabelFile = open('train.label')\n","labelline = trainlabelFile.readline()\n","\n","arrayClassCount = [ 0 for i in range(0,21)]\n","arrayDocCount = [ 0 for i in range(0,21)]\n","docdict = {}\n","cnt = 1\n","while labelline:\n","    currentlabel = labelline.strip().split()\n","    classIndex = int(currentlabel[0])\n","    docdict[cnt] = classIndex\n","    arrayDocCount[classIndex] += 1\n","    cnt += 1\n","    labelline = trainlabelFile.readline()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2XBRRKrCV-OU","colab_type":"text"},"source":["Reading train data and saving the data in a matrix, where each row represent the count of words across all documents which belongs to one class has seen the words. "]},{"cell_type":"code","metadata":{"id":"0VNnk1vbNvJW","colab_type":"code","colab":{}},"source":["traindataFile = open('train.data')\n","matrixProbabilityWord = [[1 for j in range(0,61189)] for i in range(0,21) ]\n","dataline = traindataFile.readline()\n","while dataline:\n","    currentdocword = dataline.strip().split()\n","    docIndex = int(currentdocword[0])\n","    wordIndex = int(currentdocword[1])\n","    wordCount = int(currentdocword[2])\n","    matrixProbabilityWord[docdict[docIndex]][wordIndex] += wordCount\n","    arrayClassCount[docdict[docIndex]] += wordCount\n","    dataline = traindataFile.readline()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gW18G0CGWPKJ","colab_type":"text"},"source":["Calculating the likelihoods of individual events \n","(IIDs)"]},{"cell_type":"code","metadata":{"id":"8-5ICu16R6Wj","colab_type":"code","colab":{}},"source":["for i in range(1,21):\n","    for j in range(1,61189):\n","      matrixProbabilityWord[i][j] /= arrayClassCount[i]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCa9zduYSSma","colab_type":"code","colab":{}},"source":["wordDocumentavailability = [[0 for j in range(0,61189)] for i in range(0,7506)]\n","testdataFile = open('test.data')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7lScqmPhWblP","colab_type":"text"},"source":["Reading the test data to create the boolean matrix. Each row represents the frequency of words."]},{"cell_type":"code","metadata":{"id":"bapNeUSRTAHO","colab_type":"code","colab":{}},"source":["dataline = testdataFile.readline()\n","docIndex = 0\n","while dataline:\n","    currentdocword = dataline.strip().split()\n","    docIndex = int(currentdocword[0])\n","    wordIndex = int(currentdocword[1])\n","    count = int(currentdocword[2])\n","    wordDocumentavailability[docIndex][wordIndex] = count\n","    dataline = testdataFile.readline()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YrQ0CzG3UDka","colab_type":"code","colab":{}},"source":["total_docs = 0\n","for i in range(0,21):\n","    total_docs += arrayDocCount[i]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g0EO5zyDWsot","colab_type":"text"},"source":["Calculating posterior probabilities, we are taking log of individual likelihoods(IIDs) so that we don't miss information."]},{"cell_type":"code","metadata":{"id":"isD5PbJ9UG4M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7f989859-1e04-4df5-8306-c6ad5553005c","executionInfo":{"status":"ok","timestamp":1580350196071,"user_tz":300,"elapsed":3610693,"user":{"displayName":"Sagnik Ghosh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDiUDEA00MZhuSB_RY3U58pI54keti1Ubka2vol0Nk=s64","userId":"07402194807792897169"}}},"source":["import math\n","testlabelFile = open('test.label')\n","labelline = testlabelFile.readline()\n","docId = 1\n","correctmapping = 0\n","#print(labelline)\n","\n","\n","while labelline:\n","    currentline = labelline.strip().split()\n","    classlabel = int(currentline[0])\n","    #print(classlabel)\n","    maxValue = float('-inf')\n","    prediction = 0\n","    for c in range(1,21):\n","        py = 0\n","        for word in range(1,61189):\n","        #print(word)\n","            py += wordDocumentavailability[docId][word]*math.log(matrixProbabilityWord[c][word])\n","        py += math.log(arrayDocCount[c]/total_docs)\n","        if py > maxValue:\n","            prediction = c\n","            maxValue = py\n","\n","    #print(docId,prediction)\n","    #print(prediction)\n","    if  prediction == classlabel:\n","        correctmapping+= 1\n","    labelline = testlabelFile.readline()\n","    docId += 1\n","\n","print(correctmapping)\n","                "],"execution_count":7,"outputs":[{"output_type":"stream","text":["5836\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HIdxD1npOh8O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4f9545fd-94ee-4e77-de27-125a96bdc548","executionInfo":{"status":"ok","timestamp":1580350475990,"user_tz":300,"elapsed":723,"user":{"displayName":"Sagnik Ghosh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDiUDEA00MZhuSB_RY3U58pI54keti1Ubka2vol0Nk=s64","userId":"07402194807792897169"}}},"source":["print(correctmapping/7505)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["0.7776149233844104\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pzD2ovH_W5Ug","colab_type":"text"},"source":["The success rate while treating the data as binomial distribution, yields us 77.76 % accuracy."]}]}